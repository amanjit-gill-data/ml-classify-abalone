---
title: "Classification and Pricing of Farmed Abalone"
author: "Amanjit Gill"
date: "2022-12-05"
output: 
    html_notebook:
        theme: flatly
---

```{css echo=FALSE}

h1, h2, h3 {
    font-weight: bold;
}

h1.title {
    font-size: 2em;
}

h2 {
    font-size: 1.5em;
}

h3 {
    font-size: 1.2em;
}

```


## 1. Exploratory Analysis

```{r, message=FALSE}
library(here)
library(MVN)
library(heplots)
library(e1071)
library(MASS)
library(dplyr)

select <- dplyr::select

par(
    family = "serif",
    ps = 11.5,
    mar = c(4.5, 1, 2, 1)
)

params <- par(no.readonly = TRUE)

abalone <- read.csv("abalone.csv")

# list of just the numerical variables
cols <- colnames(abalone)[-1]
```

### 1.1 Summary statistics

Statistical summary for each numerical variable.
```{r}
summary(abalone[cols])
```

Min height = 0 (impossible).

Count how many times this occurs in the data.
```{r}
n.zeros <- abalone %>% filter(Height == 0) %>% nrow()
n <- nrow(abalone)

cat(n.zeros,"out of",n)
```

Only a few occurrences. Remove from data.
```{r}
abalone <- abalone %>% filter(Height > 0)
```

Check for missing values.
```{r}

n.complete <- sum(complete.cases(abalone))
n <- nrow(abalone)

cat(n.complete,"out of",n)
```

No missing values; all rows are complete.

### 1.2 Univariate outliers

```{r}
boxplots <- function(data, colnames, pars, outfile) {

    pdf(outfile)
    par(pars)
    gridrows <- ceiling(length(colnames)/2)
    par("mfrow"=c(gridrows, 2))

    outliers <- c()
    
    for (c in colnames) {
        b <- boxplot(data[,c], horizontal = TRUE, xlab = c)
        outliers <- c(outliers, length(b$out))
    }
    
    return(data.frame(outliers, row.names = colnames))
}
```

```{r}
(outliers <- boxplots(abalone, cols, params, "1.2.pdf"))
```

![](1.2.pdf){width=100% height=500}

Every numerical variable has some outliers. However, for most of them, the number of outliers is between 0.5% and 1.5% of the sample size, so it's not clear that they will affect the analysis.

For Rings, 6.7% of the sample are outliers. This may be impactful for future analyses.

We will not remedy the outliers here. We will try transformations first, to see if these "pull in" some of the outliers.

### 1.3 Linearity and homoscedasticity

```{r}
png("1.3.png", width=1000, height=1000)
par(params)
pairs(abalone[cols])
```

<img src="1.3.png">

Non-linear relationships between all the weight variables and the length and diameter.

Heteroscedasticity between rings and all variables except height.

Oval shape implies univariate normality of whole, shucked and viscera weights.

### 1.4 Normality

Plot univariate densities to confirm normality.
```{r}
density_charts <- function(data, colnames, pars, outfile) {
    pdf(outfile)
    par(pars)
    gridrows <- ceiling(length(colnames)/2)
    par("mfrow"=c(gridrows, 2))

    for (c in colnames) {
        plot(density(data[,c]), xlab=c)
    }
}
```

```{r}
density_charts(abalone, cols, params, "1.4.pdf")
```

![](1.4.pdf){width=100% height=500}

Conduct Mardia's skewness and kurtosis test.
```{r}
mvn_test <- mvn(abalone[cols], mvnTest = "mardia", univariateTest = "SW")
mvn_test$multivariateNormality %>% select(-Statistic)
mvn_test$univariateNormality %>% select(Variable, "p value", Normality)
```

All variables exhibit departures from normality. This should be addressed because the techniques chosen for the upcoming classification and regression tasks assume normality.

### 1.5 Transformations

The following guidance will be applied:

- If negatively skewed, reflect before transformation
- If moderately different from normal: square root
- If substantially different from normal: logarithm
- If extremely different from normal: inverse

```{r}
reflect <- function(vals) {
    maxval <- max(vals)
    maxval+1 - vals
}

abalone.t <- abalone %>% mutate(
    Length = sqrt(reflect(Length)),
    Diameter = sqrt(reflect(Diameter)),
    Height = log(Height),
    Whole.weight = sqrt(Whole.weight),
    Shucked.weight = sqrt(Shucked.weight),
    Viscera.weight = sqrt(Viscera.weight),
    Shell.weight = sqrt(Shell.weight),
    Rings = sqrt(Rings),
    .keep = "unused"
)
```

Re-examine density plots to confirm improvement.
```{r}
density_charts(abalone.t, cols, params, "1.5.pdf")
```

![Density charts](1.5.pdf){width=100% height=500}

Marked improvement for all variables.

Now redo normality tests.
```{r}
mvn_test.t <- mvn(abalone.t[cols], mvnTest = "mardia", univariateTest = "SW")

"YES" %in% mvn_test.t$multivariateNormality$Result
"YES" %in% trimws(mvn_test.t$univariateNormality$Normality)
```

Still fails all tests, but this may be because the tests are more likely to fail at larger N for small deviations from normality. Let us examine and remove outliers and see if this delivers further improvements.

### 1.6 Removal of outliers

First check how many outliers remain after transformations.

```{r}
outliers.t <- boxplots(abalone.t, cols, params, "1.6.pdf")
data.frame(outliers, outliers.t)
```

![Boxplots](1.6.pdf){width=100% height=500}

table comparing original skewness and new skewness
```{r}
skew <- data.frame(mvn_test$Descriptives$Skew, mvn_test.t$Descriptives$Skew)
skew[,"Ratio"] <- abs(skew[,2]/skew[,1])
skew
```

table comparing original kurtosis and new kurtosis
```{r}
kurt <- data.frame(mvn_test$Descriptives$Kurtosis, mvn_test.t$Descriptives$Kurtosis)
kurt[,"Ratio"] <- abs(kurt[,2]/kurt[,1])
kurt
```



RESULTS:

new boxplots show far less congestion of outliers at the extremities, except for Height. this is confirmed by the comparison table, which shows a remarkable reduction in the number of outliers for every transformed variable, except, as expected, for Height. For all variables bar Height and Rings, the number of outliers is now single digits, meaning the transformations have allowed us to salvage more data points for the upcoming prediction activities.

remove remaining outliers.
```{r}
for (c in cols) {
    outs <- boxplot.stats(abalone.t[,c])$out
    abalone.t <- abalone.t %>% filter(!(abalone.t[,c] %in% outs))
}
```

### 1.7 Check

final reexamination to confirm achievement of aims.
```{r}
density_charts(abalone.t, cols, params, "1.7.pdf")

sk.final <- mvn(abalone.t[cols], mvnTest = "mardia", univariateTest = "SW")$Descriptives %>% select(Skew, Kurtosis)

sk.final
```

![Density charts](1.7.pdf){width=100% height=500}

RESULT: skewness and kurtosis are now all now below a magnitude of 1.

despite failure of SW test, can now be confident of univariate normality.

## 2. Predicting Abalone Sex

first convert response variable to factor
```{r}
abalone.t <- abalone.t %>% mutate(Sex=factor(Sex, levels=c("I", "F", "M")))
```


### 2.1. Check equal covariances assumption.

```{r}
predictors = c("Length", "Diameter", "Height")
boxM(abalone.t[,predictors], abalone.t[,"Sex"])
```
RESULT: Highly significant. Covariances are NOT equal. Therefore, start with QDA, not LDA.

### 2.2 Discriminant analysis

first try qda due to unequal variances.

```{r}
cm.da <- function(func, truevals, formula, data) {
    
    cm <- table(truth=truevals, 
                prediction=func(formula, data, CV=TRUE)$class
    )
    
    acc <- sum(diag(cm))/sum(cm)
    
    return (list(cm=cm, acc=acc))
}

cm.da(qda, abalone.t$Sex, Sex ~ Length+Diameter+Height, abalone.t)
```
RESULT: Only half of the cases were predicted correctly.

now lda because qda results are bad.
```{r}
cm.lda <- cm.da(lda, abalone.t$Sex, Sex ~ Length+Diameter+Height, abalone.t)
cm.lda
```

RESULT: LDA performs slightly better. Examine classes for which it performs well:
```{r}
acc.by.class <- function(cm) {
    
    totalcases <- sum(cm)
    
    acclist <- list()
    
    for (c in colnames(cm)) {
        acclist[c] <- cm[c,c]/sum(cm[c,])
    }
    
    return (acclist)
}

acc.by.class(cm.lda$cm)
```

RESULT: Very poor performance for predicting females. Four-fifths of females will be classified incorrectly. 

Approximately two-thirds correct predictions for infants and males. 

### 2.3 Support vector machine

first try linear kernel
```{r}
svm.and.cm <- function(truevals, formula, data, kernel, cost, gamma=NULL) {
    
    best.svm <- tune.svm(formula, data=data, kernel=kernel, 
                         cost=cost, gamma=gamma)$best.model
    
    cm <- table(
        truth=truevals,
        prediction=fitted(best.svm)
    )
    
    acc <- sum(diag(cm))/sum(cm)
    
    return (list(bestmodel=best.svm, cm=cm, acc=acc))
}

svm.lin <- svm.and.cm(abalone.t$Sex, Sex ~ Length+Diameter+Height, abalone.t,
                      kernel="linear", cost=c(0.1, 1, 10))

svm.lin$acc
```

RESULT: Not better than LDA.

now try radial kernel
```{r}
svm.rad <- svm.and.cm(abalone.t$Sex, Sex ~ Length+Diameter+Height, abalone.t,
                      kernel="radial", cost=c(0.1, 1, 10), gamma=c(0.1, 1, 10))

svm.rad$acc
```

RESULT: About the same as LDA, but slightly higher.

compute accuracy of radial SVM for each class.
```{r}
acc.by.class(svm.rad$cm)
```

Terrible accuracy for females - nearly zero.

But better accuracy for infants and males (above 70%) than QDA.

### 2.4 Diagnostics to understand poor performance of models
```{r}
sex_boxplots <- function(data, colnames, pars, outfile) {
    pdf(outfile)
    par(params)
    par("mfrow"=c(length(colnames), 1))
    
    for (c in colnames) {
        boxplot(data[,c] ~ data[,"Sex"], xlab=c)
    }
}
```

```{r}
sex_boxplots(abalone.t, predictors, params, "2.4.pdf")
```

![Boxplots](2.4.pdf){width=100% height=500}

RESULTS: Overlap between F and M for all three predictors. This may explain poor performancce of F predictions. Classifiers all seem to favour M over F. Infant data are largely separated from M and F, explaining why performance for I is consistently better for all classifiers.

### 2.5 I vs Not I

QDA
```{r}
I.notI <- abalone.t %>% mutate(Sex = gsub("[F,M]", "NotI", Sex)) %>%
    mutate(Sex=factor(Sex, levels=c("I", "NotI")))

cm.qda.I <- cm.da(qda, I.notI$Sex, Sex ~ Length+Diameter+Height, I.notI)
cm.qda.I$acc

```
LDA
```{r}
cm.lda.I <- cm.da(lda, I.notI$Sex, Sex ~ Length+Diameter+Height, I.notI)
cm.lda.I$acc
```

SVM linear kernel
```{r}
svm.lin.I <- svm.and.cm(I.notI$Sex, Sex ~ Length+Diameter+Height, I.notI,
                      kernel="linear", cost=c(0.1, 1, 10))

svm.lin.I$acc
```

SVM radial kernel
```{r}
svm.rad.I <- svm.and.cm(I.notI$Sex, Sex ~ Length+Diameter+Height, I.notI,
                      kernel="radial", cost=c(0.1, 1, 10), gamma=c(0.1, 1, 10))

svm.rad.I$acc
```

RESULTS: Best performance is SVM Radial, approaching 80% accuracy.


### 2.6 F vs Not F

```{r}
F.notF <- abalone.t %>% mutate(Sex = gsub("[I,M]", "NotF", Sex)) %>%
    mutate(Sex=factor(Sex, levels=c("F", "NotF")))

cm.qda.F <- cm.da(qda, F.notF$Sex, Sex ~ Length+Diameter+Height, F.notF)

cm.lda.F <- cm.da(lda, F.notF$Sex, Sex ~ Length+Diameter+Height, F.notF)

svm.lin.F <- svm.and.cm(F.notF$Sex, Sex ~ Length+Diameter+Height, F.notF,
                      kernel="linear", cost=c(0.1, 1, 10))

svm.rad.F <- svm.and.cm(F.notF$Sex, Sex ~ Length+Diameter+Height, F.notF,
                      kernel="radial", cost=c(0.1, 1, 10), gamma=c(0.1, 1, 10))

rbind(qda=cm.qda.F$acc, lda=cm.lda.F$acc, svm.lin=svm.lin.F$acc,
      svm.rad=svm.rad.F$acc)
```

RESULT: SVM Radial is best model. Reasonable performance at nearly 70%. 

### 2.7 M vs Not M

```{r}
M.notM <- abalone.t %>% mutate(Sex = gsub("[I,F]", "NotM", Sex)) %>%
    mutate(Sex=factor(Sex, levels=c("M", "NotM")))

cm.qda.M <- cm.da(qda, M.notM$Sex, Sex ~ Length+Diameter+Height, M.notM)

cm.lda.M <- cm.da(lda, M.notM$Sex, Sex ~ Length+Diameter+Height, M.notM)

svm.lin.M <- svm.and.cm(M.notM$Sex, Sex ~ Length+Diameter+Height, M.notM,
                      kernel="linear", cost=c(0.1, 1, 10))

svm.rad.M <- svm.and.cm(M.notM$Sex, Sex ~ Length+Diameter+Height, M.notM,
                      kernel="radial", cost=c(0.1, 1, 10), gamma=c(0.1, 1, 10))

rbind(qda=cm.qda.M$acc, lda=cm.lda.M$acc, svm.lin=svm.lin.M$acc,
      svm.rad=svm.rad.M$acc)
```
RESULT: SVM Radial gives best performance. But poorer than for F vs not F.


## 3. Profitability index

proposed methods must all rely only on data summaries:
- MLR
- PCA as an input into MLR
- CCA

### 3.1 MLR using mu and Sigma

Do each RV (shucked, viscera) separately
```{r}
mlr <- function(S, mu) {
  
  p <- length(mu)
  
  C <- S[2:p, 2:p]
  sig0 <- S[2:p, 1]

  mu.x <- mu[2:p]
  mu.y <- mu[1]

  b <- mu.y - t(sig0) %*% solve(C) %*% mu.x

  coeffs <- t(sig0) %*% solve(C)
  
  rsq <- t(sig0) %*% solve(C) %*% sig0 / S[1,1]
    
  return(list(b=b, coeffs=coeffs, rsq=rsq))
}

vars <- abalone.t %>% select(
  Shucked.weight, Viscera.weight, Length, Diameter, Height)

S.sh <- cov(vars %>% select(-Viscera.weight))
mu.sh <- colMeans(vars %>% select(-Viscera.weight))
mlr.sh <- mlr(S.sh, mu.sh)

S.vi <- cov(vars %>% select(-Shucked.weight))
mu.vi <- colMeans(vars %>% select(-Shucked.weight))
mlr.vi <- mlr(S.vi, mu.vi)
```

check the model using coeffs of determination.
```{r}
rsq.sh <- mlr.sh$rsq
rsq.vi <- mlr.vi$rsq
```

RESULT: both above 0.9. more than 90% of variation in shucked and viscera can be explained by the variation in length, diameter and height.

now check by comparing actual to predicted. first shucked.
```{r}
predict_one <- function(b, coeffs, datavals) {
  return (b + coeffs %*% datavals)
}

predict_wts <- function (mlm, datacols) {
  return (apply(datacols, 1, predict_one, b=mlm$b, coeffs=mlm$coeffs))
}

shucked.pred.mlr <- predict_wts(mlr.sh, abalone.t[,predictors])
shucked.actual <- abalone.t$Shucked.weight

plot(shucked.actual, shucked.pred.mlr); abline(a=0,b=1)
```
now viscera.
```{r}
viscera.pred.mlr <- predict_wts(mlr.vi, abalone.t[,predictors])
viscera.actual <- abalone.t$Viscera.weight

plot(viscera.actual, viscera.pred.mlr); abline(a=0,b=1)
```

### 3.2 MLR with PCs

First do PCA on IVs
```{r}
S <- cov(abalone.t %>% select(Length, Diameter, Height))

eig <- eigen(S)

p <- nrow(S)
sum_vars <- sum(eig$values)

vars <- c()
PCs <- list()
var_conts <- c()

for (i in 1:p) {
  vars <- c(vars, eig$values[i])
  PCs[[i]] <- eig$vectors[,i]
  var_conts <- c(var_conts, vars[i]/sum_vars * 100)
}

# choose k using 90% variance explained

var_conts.c <- cumsum(var_conts)
(min(which(var_conts.c >= 90)))
```

RESULT: Choose just the first PC.

Now construct a data column with the PC, then do regression.
```{r}
compute_pcs <- function (coeffs, datacols) {
  
  compute_one <- function(coeffs, datavals) {
    return (coeffs %*% datavals)
  }
  
  return (apply(datacols, 1, compute_one, coeffs=coeffs))
}

pcs <- compute_pcs(PCs[[1]], abalone.t[,predictors])
```

now predict weights. first shucked.
```{r}
predict_slr <- function(x, y) {
  
  mean_x <- mean(x)
  mean_y <- mean(y)
  r <- cor(x, y)
  sd_x <- sd(x)
  sd_y <- sd(y)
  
  b <- r * sd_y/sd_x
  a <- mean_y - b*mean_x
  
  return (list(predvals=a + b*x, rsq=r**2, a=a, b=b))
}

x <- pcs
y <- abalone.t$Shucked.weight

shucked.pred.slr <- predict_slr(x, y)
plot(shucked.actual, shucked.pred.slr$predvals); abline(a=0,b=1)
```

now viscera wt.
```{r}
x <- pcs
y <- abalone.t$Viscera.weight

viscera.pred.slr <- predict_slr(x, y)
plot(viscera.actual, viscera.pred.slr$predvals); abline(a=0,b=1)
```

RESULTS: MLR is slightly better, but not by much. Stick with MLR with observed variables.

### 3.3 Prediction interval

```{r}
PI <- function(x0, col_to_predict, mlr, alpha) {
  
  x0 <- c(1, x0)
  Z <- as.matrix(cbind(b0=1, abalone.t[,predictors]))
  sigii <- var(col_to_predict)
  
  m <- 2
  n <- nrow(abalone.t)
  r <- length(predictors)
  
  term1 <- m*(n-r-1)/(n-r-m) * qf(1-alpha, m, n-r-m)
  term2 <- 1 + t(x0) %*% solve(t(Z) %*% Z) %*% x0
  term3 <- n * sigii / (n-r-1)
  
  yhat <- t(x0) %*% cbind(c(mlr$b, mlr$coeffs))
  low <- yhat - sqrt(term1 * term2 * term3)
  high <- yhat + sqrt(term1 * term2 * term3) 
  
  return (list(yhat=yhat, low=low, high=high))
}

calc_price <- function(sh.pred, vi.pred, v.sh, v.vi) {
  sh.pred * v.sh + vi.pred * v.vi
}

est_value <- function(len, diam, height, v.sh, v.vi, alpha=0.05) {
  
  len.t <- sqrt(reflect(len))
  diam.t <- sqrt(reflect(diam))
  height.t <- log(height)
  
  x0 <- c(len.t, diam.t, height.t)
  
  sh.pred <- PI(x0, abalone.t$Shucked.weight, mlr.sh, alpha)
  vi.pred <- PI(x0, abalone.t$Viscera.weight, mlr.vi, alpha)
  
  val <- calc_price(sh.pred$yhat**2, vi.pred$yhat**2, v.sh, v.vi)
  low.val <- calc_price(sh.pred$low**2, vi.pred$low**2, v.sh, v.vi)
  high.val <- calc_price(sh.pred$high**2, vi.pred$high**2, v.sh, v.vi)
  
  return (list(round(val,2), round(low.val,2), round(high.val,2)))
}
```




