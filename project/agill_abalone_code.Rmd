---
title: "Classification and Pricing of Farmed Abalone"
author: "Amanjit Gill"
date: "2022-12-05"
output: 
    html_notebook:
        theme: flatly
---

```{css echo=FALSE}

h1, h2, h3 {
    font-weight: bold;
}

h1.title {
    font-size: 2em;
}

h2 {
    font-size: 1.5em;
}

h3 {
    font-size: 1.2em;
}

```


## 1. Exploratory Analysis

```{r setup, message=FALSE}

library(here)
library(MVN)
library(heplots)
library(e1071)
library(MASS)
library(dplyr)

select <- dplyr::select


par(
    family = "serif",
    ps = 11,
    mar = c(4.5, 1, 2, 1)
)

params <- par(no.readonly = TRUE)

abalone <- read.csv("abalone.csv")

# list of just the numerical variables
cols <- colnames(abalone)[-1]
```

### 1.1 Summary statistics

Statistical summary for each numerical variable.
```{r summary}

summary(abalone[cols])

```

RESULTS:

none of the maximum values appear to be out of range, according to sources. however:

min height = 0 (impossible).

find out how many there are, compared to how many cases there are in total.
```{r}
abalone %>% filter(Height == 0) %>% nrow()
nrow(abalone)
```

only 2 out of 4177. not a serious problem with the data. remove.
```{r}
abalone <- abalone %>% filter(Height > 0)
```


all the minimum weights are between 0.1 and 0.4 grams. not sure how realistic it is to catch and measure an abalone that tiny. may be outlier errors, or may be real.

Check for missing values.
```{r missing values}

nrow(abalone)
sum(complete.cases(abalone))
```

RESULT: No missing values; all rows are complete.

### 1.2 Univariate outliers

```{r outliers}

boxplots <- function(data, colnames, pars, outfile) {
    pdf(outfile)
    par(pars)
    gridrows <- ceiling(length(colnames)/2)
    par("mfrow"=c(gridrows, 2))

    outliers <- c()
    
    for (c in colnames) {
        b <- boxplot(data[,c], horizontal = TRUE, xlab = c)
        outliers <- c(outliers, length(b$out))
    }
    
    return(data.frame(outliers, row.names = colnames))
}

outliers <- boxplots(abalone, cols, params, "1.2.pdf")

```

RESULTS: 

every numerical variable has some outliers.
however, for 7 of them, the number of outliers is between 0.5 and 1.5% of the sample size, so it's not clear that they will affect the analysis.
for the 8th, Rings, there are 278 outliers, 6.7% of the sample size. This may be impactful, and should be confirmed as being so.

we will not remedy the outliers here. we will try transformations first, to see if some of outliers have been pulled in.

### 1.3 Linearity and homoscedasticity

```{r linearity}
pdf("1.3.pdf")
par(params)

pairs(abalone[cols])
```

RESULTS:

non-linear between all the weights and the length and diameter

heteroscedasticity between rings and everything except for height

oval shape implies univariate normality of whole, shucked and viscera weights
others are too hard to tell


### 1.4 Normality

```{r normality}

density_charts <- function(data, colnames, pars, outfile) {
    pdf(outfile)
    par(pars)
    gridrows <- ceiling(length(colnames)/2)
    par("mfrow"=c(gridrows, 2))

    for (c in colnames) {
        plot(density(data[,c]), xlab=c)
    }
}

density_charts(abalone, cols, params, "1.4.pdf")

```

Mardia's skewness and kurtosis test
```{r mardia}

mvn_test <- mvn(abalone[cols], mvnTest = "mardia", univariateTest = "SW")

```

### 1.5 Transformations

moderately different from normal: square root

substantially different from normal: logarithm

extremely different from normal: inverse


apply following transformations:

|Variable|Transformation|
|:--------|:--------------|
|Length|Reflect and square root|
|Diameter|Reflect and square root|
|Height|Logarithm|
|Whole weight|Square root|
|Shucked weight|Square root|
|Viscera weight|Square root|
|Shell weight|Square root|
|Rings|Square root|


```{r}

reflect <- function(vals) {
    maxval <- max(vals)
    maxval+1 - vals
}


abalone.t <- abalone %>% mutate(
    Length = sqrt(reflect(Length)),
    Diameter = sqrt(reflect(Diameter)),
    Height = log(Height),
    Whole.weight = sqrt(Whole.weight),
    Shucked.weight = sqrt(Shucked.weight),
    Viscera.weight = sqrt(Viscera.weight),
    Shell.weight = sqrt(Shell.weight),
    Rings = sqrt(Rings),
    .keep = "unused"
)

```

recheck normality
```{r}

density_charts(abalone.t, cols, params, "1.5.pdf")
mvn_test.t <- mvn(abalone.t[cols], mvnTest = "mardia", univariateTest = "SW")
```

still fails all tests, but this is because the tests are more likely to fail at larger N for small deviations. visually, they look mostly normal, which matters more than the hyp test.

much improved skewness - very small compared to original data

for kurtosis, most variables have gone from slightly positive (too peaked) to slightly negative (too flat), but the magnitudes are 1 or below, with the exception of Height, which has experienced a marked improvement (from 76.62 to 4.57).

kurtosis generally does not affect estimates of variance for large sample sizes, so these transformations are considered acceptable.

table comparing original skewness and new skewness
```{r}
skew <- data.frame(mvn_test$Descriptives$Skew, mvn_test.t$Descriptives$Skew)
skew[,"Ratio"] <- abs(skew[,2]/skew[,1])
skew
```

table comparing original kurtosis and new kurtosis
```{r}
kurt <- data.frame(mvn_test$Descriptives$Kurtosis, mvn_test.t$Descriptives$Kurtosis)
kurt[,"Ratio"] <- abs(kurt[,2]/kurt[,1])
kurt
```


### 1.6 Removal of outliers

first recheck how many outliers remain after transformation.

```{r}
outliers.t <- boxplots(abalone.t, cols, params, "1.6.pdf")
data.frame(outliers, outliers.t)
```

RESULTS:

new boxplots show far less congestion of outliers at the extremities, except for Height. this is confirmed by the comparison table, which shows a remarkable reduction in the number of outliers for every transformed variable, except, as expected, for Height. For all variables bar Height and Rings, the number of outliers is now single digits, meaning the transformations have allowed us to salvage more data points for the upcoming prediction activities.

remove remaining outliers.
```{r}
for (c in cols) {
    outs <- boxplot.stats(abalone.t[,c])$out
    abalone.t <- abalone.t %>% filter(!(abalone.t[,c] %in% outs))
}
```

### 1.7 Check

final reexamination to confirm achievement of aims.
```{r}
density_charts(abalone.t, cols, params, "1.7.pdf")

sk.final <- mvn(abalone.t[cols], mvnTest = "mardia", univariateTest = "SW")$Descriptives %>% select(Skew, Kurtosis)

sk.final
```

RESULT: skewness and kurtosis are now all now below a magnitude of 1.

despite failure of SW test, can now be confident of univariate normality.

## 2. Predicting Abalone Sex

first convert response variable to factor
```{r}
abalone.t <- abalone.t %>% mutate(Sex=factor(Sex, levels=c("I", "F", "M")))
```


### 2.1. Check equal covariances assumption.

```{r}

predictors = c("Length", "Diameter", "Height")
boxM(abalone.t[,predictors], abalone.t[,"Sex"])

```
RESULT: Highly significant. Covariances are NOT equal. Therefore, start with QDA, not LDA.

### 2.2 Discriminant analysis

first try qda due to unequal variances.

```{r}

cm.da <- function(func, truevals, formula, data) {
    
    cm <- table(truth=truevals, 
                prediction=func(formula, data, CV=TRUE)$class
    )
    
    acc <- sum(diag(cm))/sum(cm)
    
    return (list(cm=cm, acc=acc))
}

cm.da(qda, abalone.t$Sex, Sex ~ Length+Diameter+Height, abalone.t)

```
RESULT: Only half of the cases were predicted correctly.

now lda because qda results are bad.
```{r}
cm.lda <- cm.da(lda, abalone.t$Sex, Sex ~ Length+Diameter+Height, abalone.t)
cm.lda
```

RESULT: LDA performs slightly better. Examine classes for which it performs well:
```{r}
acc.by.class <- function(cm) {
    
    totalcases <- sum(cm)
    
    acclist <- list()
    
    for (c in colnames(cm)) {
        acclist[c] <- cm[c,c]/sum(cm[c,])
    }
    
    return (acclist)
}

acc.by.class(cm.lda$cm)

```

RESULT: Very poor performance for predicting females. Four-fifths of females will be classified incorrectly. 

Approximately two-thirds correct predictions for infants and males. 

### 2.3 Support vector machine

first try linear kernel
```{r}
svm.and.cm <- function(truevals, formula, data, kernel, cost, gamma=NULL) {
    
    best.svm <- tune.svm(formula, data=data, kernel=kernel, 
                         cost=cost, gamma=gamma)$best.model
    
    cm <- table(
        truth=truevals,
        prediction=fitted(best.svm)
    )
    
    acc <- sum(diag(cm))/sum(cm)
    
    return (list(bestmodel=best.svm, cm=cm, acc=acc))
}

svm.lin <- svm.and.cm(abalone.t$Sex, Sex ~ Length+Diameter+Height, abalone.t,
                      kernel="linear", cost=c(0.1, 1, 10))

svm.lin$acc

```

RESULT: Not better than LDA.

now try radial kernel
```{r}

svm.rad <- svm.and.cm(abalone.t$Sex, Sex ~ Length+Diameter+Height, abalone.t,
                      kernel="radial", cost=c(0.1, 1, 10), gamma=c(0.1, 1, 10))

svm.rad$acc

```

RESULT: About the same as LDA, but slightly higher.

compute accuracy of radial SVM for each class.
```{r}

acc.by.class(svm.rad$cm)
```

Terrible accuracy for females - nearly zero.

But better accuracy for infants and males (above 70%) than QDA.

### 2.4 Diagnostics to understand poor performance of models
```{r}
sex_boxplots <- function(data, colnames, pars, outfile) {
    pdf(outfile)
    par(params)
    par("mfrow"=c(length(colnames), 1))
    
    for (c in colnames) {
        boxplot(data[,c] ~ data[,"Sex"], xlab=c)
    }
}

sex_boxplots(abalone.t, predictors, params, "2.4.pdf")
```

RESULTS: Overlap between F and M for all three predictors. This may explain poor performancce of F predictions. Classifiers all seem to favour M over F. Infant data are largely separated from M and F, explaining why performance for I is consistently better for all classifiers.

So how do we separate M cases from F cases?

How about age (Rings)?
```{r}
sex_boxplots(abalone.t, c("Rings"), params, "2.4a.pdf")
```

RESULT: Good separation of I from F and M, but still considerable overlap of F and M. F is completely subsumed by M, and even has nearly the same median.

### 2.5 I vs Not I

QDA
```{r}
I.notI <- abalone.t %>% mutate(Sex = gsub("[F,M]", "NotI", Sex)) %>%
    mutate(Sex=factor(Sex, levels=c("I", "NotI")))

cm.qda.I <- cm.da(qda, I.notI$Sex, Sex ~ Length+Diameter+Height, I.notI)
cm.qda.I$acc

```
LDA
```{r}
cm.lda.I <- cm.da(lda, I.notI$Sex, Sex ~ Length+Diameter+Height, I.notI)
cm.lda.I$acc
```

SVM linear kernel
```{r}

svm.lin.I <- svm.and.cm(I.notI$Sex, Sex ~ Length+Diameter+Height, I.notI,
                      kernel="linear", cost=c(0.1, 1, 10))

svm.lin.I$acc
```

SVM radial kernel
```{r}
svm.rad.I <- svm.and.cm(I.notI$Sex, Sex ~ Length+Diameter+Height, I.notI,
                      kernel="radial", cost=c(0.1, 1, 10), gamma=c(0.1, 1, 10))

svm.rad.I$acc
```

RESULTS: Best performance is SVM Radial.

But infants should theoretically have fewer rings than adult f/m. So can Rings help us separate I from notI?
```{r}
sex_boxplots(I.notI, c("Rings"), params, "2.5.pdf")

```

RESULT: Can see that IQR for infants ends where IQR for adults starts.

This can be used as a threshold between I and notI.
```{r}
justI <- I.notI %>% filter(Sex == "I")
threshold <- quantile(justI$Rings)["75%"]

lowR <- I.notI %>% filter(Rings <= threshold)
highR <- I.notI %>% filter(Rings > threshold)

low.high <- rbind(table(lowR$Sex), table(highR$Sex))
row.names(low.high) <- c("Rings<=threshold", "Rings>threshold")

low.high <- cbind(low.high, proportionI=low.high[,1]/rowSums(low.high))
low.high
```

RESULT:

For high Rings, nearly 88% of cases are not I. This is a remarkable result because it means that for high Rings, simply allocating it to NotI works better than the classifiers.

By contrast, for low Rings, approx half of cases are I, and half are not I, meaning that for low Rings, the physical dimensions (length, etc) perform better.

This leaves us with the following algorithm:

if high Rings, class = NotI
if low Rings, class = use classifier (SVM Radial)

### 2.6 F vs Not F

```{r}
F.notF <- abalone.t %>% mutate(Sex = gsub("[I,M]", "NotF", Sex)) %>%
    mutate(Sex=factor(Sex, levels=c("F", "NotF")))

cm.qda.F <- cm.da(qda, F.notF$Sex, Sex ~ Length+Diameter+Height, F.notF)

cm.lda.F <- cm.da(lda, F.notF$Sex, Sex ~ Length+Diameter+Height, F.notF)

svm.lin.F <- svm.and.cm(F.notF$Sex, Sex ~ Length+Diameter+Height, F.notF,
                      kernel="linear", cost=c(0.1, 1, 10))

svm.rad.F <- svm.and.cm(F.notF$Sex, Sex ~ Length+Diameter+Height, F.notF,
                      kernel="radial", cost=c(0.1, 1, 10), gamma=c(0.1, 1, 10))

rbind(qda=cm.qda.F$acc, lda=cm.lda.F$acc, svm.lin=svm.lin.F$acc,
      svm.rad=svm.rad.F$acc)

```

RESULT: SVM Radial is best model. Reasonable performance at nearly 70%. 

See if Rings can help like with infants. Not likely, but worth a try.
```{r}
sex_boxplots(F.notF, c("Rings"), params, "2.6.pdf")
```

RESULT: Too much overlap, not much scope for improvement. Stick with SVM Radial.

### 2.7 M vs Not M

```{r}
M.notM <- abalone.t %>% mutate(Sex = gsub("[I,F]", "NotM", Sex)) %>%
    mutate(Sex=factor(Sex, levels=c("M", "NotM")))

cm.qda.M <- cm.da(qda, M.notM$Sex, Sex ~ Length+Diameter+Height, M.notM)

cm.lda.M <- cm.da(lda, M.notM$Sex, Sex ~ Length+Diameter+Height, M.notM)

svm.lin.M <- svm.and.cm(M.notM$Sex, Sex ~ Length+Diameter+Height, M.notM,
                      kernel="linear", cost=c(0.1, 1, 10))

svm.rad.M <- svm.and.cm(M.notM$Sex, Sex ~ Length+Diameter+Height, M.notM,
                      kernel="radial", cost=c(0.1, 1, 10), gamma=c(0.1, 1, 10))

rbind(qda=cm.qda.M$acc, lda=cm.lda.M$acc, svm.lin=svm.lin.M$acc,
      svm.rad=svm.rad.M$acc)
```
RESULT: SVM Radial gives best performance. But poorer than for F vs not F.

See if Rings can help like with infants. Not likely, but worth a try.
```{r}
sex_boxplots(M.notM, c("Rings"), params, "2.7.pdf")
```

RESULT: Considerable overlap, not much scope for improvement. Stick with SVM Radial.

## 3. Profitability index

proposed methods must all rely only on data summaries:
- MLR
- PCA as an input into MLR
- CCA

### 3.1 MLR using mu and Sigma

Do each RV (shucked, viscera) separately
```{r}

mlr <- function(S, mu) {
  
  p <- length(mu)
  
  C <- S[2:p, 2:p]
  sig0 <- S[2:p, 1]

  mu.x <- mu[2:p]
  mu.y <- mu[1]

  b <- mu.y - t(sig0) %*% solve(C) %*% mu.x

  coeffs <- t(sig0) %*% solve(C)
  
  rsq <- t(sig0) %*% solve(C) %*% sig0 / S[1,1]
    
  return(list(b=b, coeffs=coeffs, rsq=rsq))
}

vars <- abalone.t %>% select(
  Shucked.weight, Viscera.weight, Length, Diameter, Height)

S.sh <- cov(vars %>% select(-Viscera.weight))
mu.sh <- colMeans(vars %>% select(-Viscera.weight))
mlr.sh <- mlr(S.sh, mu.sh)

S.vi <- cov(vars %>% select(-Shucked.weight))
mu.vi <- colMeans(vars %>% select(-Shucked.weight))
mlr.vi <- mlr(S.vi, mu.vi)
```

check the model using coeffs of determination.
```{r}

rsq.sh <- mlr.sh$rsq
rsq.vi <- mlr.vi$rsq
```

RESULT: both above 0.9. more than 90% of variation in shucked and viscera can be explained by the variation in length, diameter and height.

now check by comparing actual to predicted. first shucked.
```{r}

predict_wts <- function (mlm, datacols) {
  
  predict_one <- function(b, coeffs, datavals) {
    return (b + coeffs %*% datavals)
  }
  
  return (apply(datacols, 1, predict_one, b=mlm$b, coeffs=mlm$coeffs))
}

shucked.pred.mlr <- predict_wts(mlr.sh, abalone.t[,predictors])
shucked.actual <- abalone.t$Shucked.weight

plot(shucked.actual, shucked.pred.mlr); abline(a=0,b=1)
```
now viscera.
```{r}
viscera.pred.mlr <- predict_wts(mlr.vi, abalone.t[,predictors])
viscera.actual <- abalone.t$Viscera.weight

plot(viscera.actual, viscera.pred.mlr); abline(a=0,b=1)
```

### 3.2 MLR with PCs

First do PCA on IVs
```{r}

S <- cov(abalone.t %>% select(Length, Diameter, Height))

eig <- eigen(S)

p <- nrow(S)
sum_vars <- sum(eig$values)

vars <- c()
PCs <- list()
var_conts <- c()

for (i in 1:p) {
  vars <- c(vars, eig$values[i])
  PCs[[i]] <- eig$vectors[,i]
  var_conts <- c(var_conts, vars[i]/sum_vars * 100)
}

# choose k using 90% variance explained

var_conts.c <- cumsum(var_conts)
(min(which(var_conts.c >= 90)))

```

RESULT: Choose just the first PC.

Now construct a data column with the PC, then do regression.
```{r}

compute_pcs <- function (coeffs, datacols) {
  
  compute_one <- function(coeffs, datavals) {
    return (coeffs %*% datavals)
  }
  
  return (apply(datacols, 1, compute_one, coeffs=coeffs))
}

pcs <- compute_pcs(PCs[[1]], abalone.t[,predictors])

```

now predict weights. first shucked.
```{r}

predict_slr <- function(x, y) {
  
  mean_x <- mean(x)
  mean_y <- mean(y)
  r <- cor(x, y)
  sd_x <- sd(x)
  sd_y <- sd(y)
  
  b <- r * sd_y/sd_x
  a <- mean_y - b*mean_x
  
  return (list(predvals=a + b*x, rsq=r**2, a=a, b=b))
}

x <- pcs
y <- abalone.t$Shucked.weight

shucked.pred.slr <- predict_slr(x, y)
plot(shucked.actual, shucked.pred.slr$predvals); abline(a=0,b=1)

```

now viscera wt.
```{r}
x <- pcs
y <- abalone.t$Viscera.weight

viscera.pred.slr <- predict_slr(x, y)
plot(viscera.actual, viscera.pred.slr$predvals); abline(a=0,b=1)
```

RESULTS: MLR is slightly better, but not by much. Stick with MLR with observed variables.

### 3.3 Prediction interval

```{r}

# for shucked wt; x0 = new observation
x0 <- rbind(1,1,2,3)
yhat <- t(x0) %*% cbind(c(mlr.sh$b, mlr.sh$coeffs))

Z <- as.matrix(cbind(b0=1, abalone.t[,predictors]))
sigii <- var(abalone.t$Shucked.weight)

m <- 2
n <- nrow(abalone.t)
r <- length(predictors)

alpha <- 0.05

term1 <- m*(n-r-1)/(n-r-m) * qf(1-alpha, m, n-r-m)
term2 <- 1 + t(x0) %*% solve(t(Z) %*% Z) %*% x0
term3 <- n * sigii / (n-r-1)

low <- yhat - sqrt(term1 * term2 * term3)
high <- yhat + sqrt(term1 * term2 * term3) 

est_value <- function(len, diam, height, v.sh, v.vi, alpha=0.9) {
  
  predict shucked weight
  predict viscera weight
  
  val <- shucked weight * v.sh + viscera weight * v.vi
  
  low.sh <- ETC
  high.sh <- ETC
  low.vi <- ETC
  high.vi <- ETC
  
  low.val <- low.sh * v.sh + low.vi * v.vi
  high.val <- high.sh * v.sh + high.sh * v.vi
  
  return (list(val, low.val, high.val))
}


```




